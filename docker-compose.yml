x-logging: &default-logging
  driver: "json-file"
  options:
    max-size: "1m"
    max-file: "1"
    tag: "{{.Name}}"

x-common-labels: &default-labels
  logging: "promtail"
  logging_jobname: "containerlogs"
  stackname: "docker-monitoring-stack-gpnc"

services:
  traefik:
    image: traefik:v3.1
    container_name: traefik
    command:
      - --providers.docker
      - --providers.docker.exposedbydefault=false
      - --entrypoints.http.address=:80
      - --entrypoints.https.address=:443
      - --certificatesresolvers.le.acme.email=${ACME_EMAIL}
      - --certificatesresolvers.le.acme.storage=/letsencrypt/acme.json
      - --certificatesresolvers.le.acme.httpchallenge=true
      - --certificatesresolvers.le.acme.httpchallenge.entrypoint=http
    ports:
      - 80:80
      - 443:443
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./letsencrypt:/letsencrypt
    networks:
      - traefik-public
    restart: unless-stopped

  mt5:
    build:
      context: ./backend/mt5
      dockerfile: Dockerfile
    container_name: mt5
    volumes:
      - ./config:/config
      - ./mt5_gateway:/opt/mt5_gateway:ro
    networks:
      - traefik-public
      - default
    env_file:
      - .env
    restart: unless-stopped
    labels:
      <<: *default-labels
      # Enable Traefik for this service
      traefik.enable: true
      traefik.docker.network: traefik-public

      # Router for vnc.mt5.${domain} (Port 3000)
      traefik.http.routers.vnc-mt5-http.rule: Host(`${VNC_DOMAIN}`)
      traefik.http.routers.vnc-mt5-http.entrypoints: http
      traefik.http.routers.vnc-mt5-http.middlewares: https-redirect
      traefik.http.routers.vnc-mt5-http.service: vnc-mt5-service

      traefik.http.routers.vnc-mt5-https.rule: Host(`${VNC_DOMAIN}`)
      traefik.http.routers.vnc-mt5-https.entrypoints: https
      traefik.http.routers.vnc-mt5-https.tls: true
      traefik.http.routers.vnc-mt5-https.tls.certresolver: le
      traefik.http.routers.vnc-mt5-https.service: vnc-mt5-service

      traefik.http.services.vnc-mt5-service.loadbalancer.server.port: 3000

      # API routing moved to dedicated mt5-api service (to avoid conflicts)
      x-traefik.disabled.api-mt5-http.rule: Host(`${API_DOMAIN}`)
      x-traefik.disabled.api-mt5-http.entrypoints: http
      x-traefik.disabled.api-mt5-http.middlewares: https-redirect
      x-traefik.disabled.api-mt5-http.service: api-mt5-service

      x-traefik.disabled.api-mt5-https.rule: Host(`${API_DOMAIN}`)
      x-traefik.disabled.api-mt5-https.entrypoints: https
      x-traefik.disabled.api-mt5-https.tls: true
      x-traefik.disabled.api-mt5-https.tls.certresolver: le
      x-traefik.disabled.api-mt5-https.service: api-mt5-service
    logging: *default-logging
    depends_on:
      - traefik

  mt5-api:
    image: python:3.11-slim
    container_name: mt5-api
    working_dir: /app
    volumes:
      - ./backend/mt5_api:/app
    command: sh -lc "pip install --no-cache-dir fastapi uvicorn requests && uvicorn app:app --host 0.0.0.0 --port 5001"
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - MT5_API_URL=http://mt5:5001
      - MT5_URL=http://mt5:5001
      - DJANGO_API_URL=http://django:8000
      - DJANGO_API_PREFIX=/api/v1
      - BRIDGE_TOKEN=${BRIDGE_TOKEN:-}
      - MT5_API_STUB_FALLBACK=1
    networks:
      - traefik-public
      - default
    labels:
      <<: *default-labels
      traefik.enable: true
      traefik.docker.network: traefik-public

      # API router bound to API_DOMAIN
      traefik.http.routers.api-mt5-http.rule: Host(`${API_DOMAIN}`)
      traefik.http.routers.api-mt5-http.entrypoints: http
      traefik.http.routers.api-mt5-http.middlewares: https-redirect
      traefik.http.routers.api-mt5-http.service: api-mt5-service

      traefik.http.routers.api-mt5-https.rule: Host(`${API_DOMAIN}`)
      traefik.http.routers.api-mt5-https.entrypoints: https
      traefik.http.routers.api-mt5-https.tls: true
      traefik.http.routers.api-mt5-https.tls.certresolver: le
      traefik.http.routers.api-mt5-https.service: api-mt5-service

      traefik.http.services.api-mt5-service.loadbalancer.server.port: 5001
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s

  postgres:
    image: postgres:15-alpine
    container_name: postgres
    restart: unless-stopped
    env_file:
      - .env
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-postgres}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - default
    labels:
      <<: *default-labels
    logging: *default-logging

  django:
    build:
      context: .
      dockerfile: backend/django/Dockerfile
    container_name: django
    working_dir: /app/backend/django
    volumes:
      - static_volume:/app/staticfiles
      - ./data/cold:/app/data/cold
      - ./agents:/app/agents
    restart: unless-stopped
    ports:
      - 8010:8000
    env_file:
      - .env
    environment:
      - PYTHONPATH=/app:/app/components:/app/utils:/app/backend:/app/agents
      - DJANGO_SETTINGS_MODULE=app.settings
      - DJANGO_SECRET_KEY=${DJANGO_SECRET_KEY:-dev-insecure-key-change-me}
      - DJANGO_DOMAIN=${DJANGO_DOMAIN:-localhost}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
      - ALERTS_ENABLED=true
      - ALERTS_MIN_INTERVAL_SECONDS=60
      - ALERTS_SCORE_HI=90
      - ALERTS_TOXICITY_LIMIT=0.30
      - ALERTS_DD_INTRADAY_WARN=0.025
      - MT5_API_URL=http://mt5:5001
      # Avoid overriding secret key with empty value; single definition above is sufficient
    depends_on:
      postgres:
        condition: service_healthy
      traefik:
        condition: service_started
      redis:
        condition: service_healthy
    networks:
      - default
      - traefik-public
    labels:
      <<: *default-labels
      traefik.enable: true
      traefik.docker.network: traefik-public

      traefik.http.routers.django-http.rule: 'HostRegexp(`{domain: zanalytics\.app}`) && !Host(`mcp2.zanalytics.app`)'
      traefik.http.routers.django-http.entrypoints: http
      traefik.http.routers.django-http.middlewares: https-redirect
      traefik.http.routers.django-http.service: django-service

      traefik.http.routers.django-https.rule: 'HostRegexp(`{domain: zanalytics\.app}`) && !Host(`mcp2.zanalytics.app`)'
      traefik.http.routers.django-https.entrypoints: https
      traefik.http.routers.django-https.tls: true
      traefik.http.routers.django-https.tls.certresolver: le
      traefik.http.routers.django-https.service: django-service

      traefik.http.services.django-service.loadbalancer.server.port: 8000

      traefik.http.routers.django-static.rule: Host(`${DJANGO_DOMAIN}`) && PathPrefix(`/static/`)
      traefik.http.routers.django-static.service: django-service
      traefik.http.middlewares.static-stripprefix.stripprefix.prefixes: /static
      traefik.http.routers.django-static.middlewares: static-stripprefix@docker
    healthcheck:
      test: ["CMD-SHELL", "python -c \"import urllib.request,sys; sys.exit(0) if urllib.request.urlopen('http://localhost:8000/api/pulse/health').getcode()==200 else sys.exit(1)\""]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    logging: *default-logging


  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - 6379:6379
    volumes:
      - redis-data:/data
      - ./redis_architecture/redis.conf:/usr/local/etc/redis/redis.conf
    environment:
      - PYTHONPATH=/app:/app/components:/app/utils
      - PULSE_API_URL=http://django:8000
      - MT5_API_URL=http://mt5:5001
      - MT5_API_BASE=http://mt5:5001
      - PULSE_API_BASE=http://django:8000
      - REDIS_HOST=redis
    command: redis-server /usr/local/etc/redis/redis.conf
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - default
    labels:
      <<: *default-labels
    logging: *default-logging

  celery:
    build:
      context: .
      dockerfile: backend/django/Dockerfile
    container_name: celery
    working_dir: /app/backend/django
    entrypoint: ["sh", "-c", "celery -A app worker --loglevel=info --concurrency=${CELERY_CONCURRENCY:-3}"]
    volumes:
      - static_volume:/app/staticfiles
      - ./data/cold:/app/data/cold
      - ./agents:/app/agents
    env_file:
      - .env
    environment:
      - PYTHONPATH=/app/backend/django:/app/agents:/app:/app/components:/app/utils:/app/backend
      - DJANGO_SETTINGS_MODULE=app.settings
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - CELERY_APP=app
    depends_on:
      django:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - default
    labels:
      <<: *default-labels
    logging: *default-logging

  celery-beat:
    build:
      context: .
      dockerfile: backend/django/Dockerfile
    container_name: celery-beat
    working_dir: /app/backend/django
    entrypoint: ["sh", "-c", "celery -A app beat --loglevel=info"]
    volumes:
      - static_volume:/app/staticfiles
      - ./data/cold:/app/data/cold
      - ./agents:/app/agents
    env_file:
      - .env
    environment:
      - PYTHONPATH=/app/backend/django:/app/agents:/app:/app/components:/app/utils:/app/backend
      - DJANGO_SETTINGS_MODULE=app.settings
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - CELERY_APP=app
    depends_on:
      celery:
        condition: service_started
      redis:
        condition: service_healthy
    networks:
      - default
    labels:
      <<: *default-labels
    logging: *default-logging

  grafana:
    image: grafana/grafana:${GRAFANA_VERSION:-11.0.0}
    container_name: grafana
    restart: unless-stopped
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
      - GF_USERS_DEFAULT_THEME=dark
      - GF_LOG_MODE=console
      - GF_LOG_LEVEL=critical
      - GF_PANELS_ENABLE_ALPHA=true
      - GF_FEATURE_TOGGLES_ENABLE=accessControlOnCall lokiLogsDataplane
      - GF_INSTALL_PLUGINS=grafana-polystat-panel,https://storage.googleapis.com/integration-artifacts/grafana-lokiexplore-app/grafana-lokiexplore-app-latest.zip;grafana-lokiexplore-app
    volumes:
      - ./monitoring/configs/grafana/provisioning/dashboards.yml:/etc/grafana/provisioning/dashboards/provisioning-dashboards.yaml:ro
      - ./monitoring/configs/grafana/provisioning/datasources.yml:/etc/grafana/provisioning/datasources/provisioning-datasources.yaml:ro
      - ./monitoring/configs/grafana/plugins/app.yaml:/etc/grafana/provisioning/plugins/app.yaml:ro
      - ./monitoring/dashboards/node-metrics.json:/var/lib/grafana/dashboards/node-metrics.json:ro
      - ./monitoring/dashboards/container-metrics.json:/var/lib/grafana/dashboards/container-metrics.json:ro
      - ./monitoring/dashboards/log-search.json:/var/lib/grafana/dashboards/log-search.json:ro
      - ./monitoring/dashboards/traefik_official.json:/var/lib/grafana/dashboards/traefik_official.json:ro
      - ./monitoring/dashboards/altertmanager-dashboard.json:/var/lib/grafana/dashboards/altertmanager-dashboard.json:ro
      - ./monitoring/dashboards/mcp-pulse.json:/var/lib/grafana/dashboards/mcp-pulse.json:ro
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
      - traefik
    ports:
      - 3000:3000
    cpus: 0.5
    mem_limit: 512m
    networks:
      - default
      - traefik-public
    labels:
      <<: *default-labels
      traefik.enable: true
      traefik.docker.network: traefik-public
      traefik.http.routers.grafana.rule: Host(`${GRAFANA_DOMAIN?Variable not set}`)
      traefik.http.routers.grafana.entrypoints: https
      traefik.http.routers.grafana.tls: true
      traefik.http.routers.grafana.tls.certresolver: le
      traefik.http.services.grafana.loadbalancer.server.port: 3000
    logging: *default-logging

  prometheus:
    image: prom/prometheus:${PROMETHEUS_VERSION:-v2.42.0}
    container_name: prometheus
    restart: unless-stopped
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--log.level=error"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=7d"
      - "--web.console.libraries=/usr/share/prometheus/console_libraries"
      - "--web.console.templates=/usr/share/prometheus/consoles"
      - "--web.external-url=http://localhost:9090"
    volumes:
      - ./monitoring/configs/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - ./monitoring/configs/prometheus/recording-rules.yml:/etc/prometheus/recording-rules.yml
      - ./monitoring/configs/prometheus/alerting-rules.yml:/etc/prometheus/alerting-rules.yml
      - prometheus-data:/prometheus
    depends_on:
      - alertmanager
      - traefik
    ports:
      - 9090:9090
    cpus: 0.5
    mem_limit: 512m
    networks:
      - default
    labels:
      <<: *default-labels
    logging: *default-logging

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:${CADVISOR_VERSION:-v0.46.0}
    container_name: cadvisor
    restart: unless-stopped
    privileged: true
    depends_on:
      - traefik
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
        # https://github.com/google/cadvisor/issues/1565#issuecomment-718812180
      - /var/run/docker.sock:/var/run/docker.sock
      #- /dev/disk:/dev/disk:ro
    cpus: 0.5
    mem_limit: 512m
    networks:
      - default
    labels:
      <<: *default-labels
    logging: *default-logging

  node-exporter:
    image: prom/node-exporter:${NODE_EXPORTER_VERSION:-v1.5.0}
    container_name: node-exporter
    restart: unless-stopped
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - "--path.procfs=/host/proc"
      - "--path.sysfs=/host/sys"
      - "--collector.filesystem.ignored-mount-points"
      - "^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)"
    depends_on:
      - traefik
    cpus: 0.5
    mem_limit: 512m
    networks:
      - default
    labels:
      <<: *default-labels
    logging: *default-logging

  alertmanager:
    image: prom/alertmanager:${ALERTMANAGER_VERSION:-v0.25.0}
    container_name: alertmanager
    command:
      - "--config.file=/etc/alertmanager/config.yml"
      - "--log.level=error"
      - "--storage.path=/alertmanager"
      - "--web.external-url=http://localhost:9093"
    volumes:
      - ./monitoring/configs/alertmanager/alertmanager-fallback-config.yml:/etc/alertmanager/config.yml
    ports:
      - 9093:9093
    cpus: 0.5
    mem_limit: 512m
    networks:
      - default
    depends_on:
      - uncomplicated-alert-receiver
      - traefik
    labels:
      <<: *default-labels
    logging: *default-logging

  uncomplicated-alert-receiver:
    image: ghcr.io/jamesread/uncomplicated-alert-receiver
    container_name: uncomplicated-alert-receiver
    ports:
      - 9094:8080
    cpus: 0.5
    mem_limit: 512m
    networks:
      - default
    depends_on:
      - traefik
    labels:
      <<: *default-labels
    logging: *default-logging

  loki:
    image: grafana/loki:3.0.0
    container_name: loki
    user: root
    ports:
      - 3100:3100
    command: -config.file=/etc/loki/loki.yaml
    volumes:
      - ./monitoring/configs/loki/loki.yaml:/etc/loki/loki.yaml
      - ./monitoring/configs/loki/rules.yaml:/etc/loki/rules/fake/loki-rules.yml
    depends_on:
      - traefik
    cpus: 0.5
    mem_limit: 512m
    networks:
      - default
    labels:
      <<: *default-labels
    logging: *default-logging

  promtail:
    image: grafana/promtail:3.0.0
    container_name: promtail
    volumes:
      - ./monitoring/configs/promtail/promtail.yaml:/etc/promtail/docker-config.yaml
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: -config.file=/etc/promtail/docker-config.yaml
    depends_on:
      - loki
      - traefik
    cpus: 0.5
    mem_limit: 512m
    networks:
      - default
    labels:
      <<: *default-labels
    logging: *default-logging

  tick-to-bar:
    build:
      context: .
      dockerfile: Dockerfile.tick-to-bar
    command: ["python", "services/tick_to_bar.py"]
    environment:
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - SYMBOL=EURUSD
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN:-}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID:-}
    volumes:
      - .:/app
    depends_on:
      - redis
    restart: unless-stopped
    networks:
      - default

  pulse-kernel:
    build: .
    command: python -m uvicorn services.pulse_api.main:app --host 0.0.0.0 --port 8000
    environment:
      - PULSE_CONFIG=/app/pulse_config.yaml
      - PULSE_JOURNAL_PATH=/app/data/journal
      - PYTHONPATH=/app:/app/services:/app/pulse_kernel
    volumes:
      - ./pulse_kernel.py:/app/pulse_kernel.py
      - ./pulse_config.yaml:/app/pulse_config.yaml
      - ./data/journal:/app/data/journal
    depends_on:
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
      django:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/pulse/health"]
      interval: 15s
      timeout: 5s
      retries: 10

  dashboard:
    build:
      context: ./dashboard
      dockerfile: Dockerfile
    container_name: dashboard
    working_dir: /app/dashboard
    volumes:
      - ./dashboard:/app/dashboard
      - ./components:/app/components
      - ./utils:/app/utils
      - ./api_integration:/app/api_integration
      - ./dashboard/.streamlit:/app/dashboard/.streamlit
    env_file:
      - .env
    environment:
      - PYTHONPATH=/app:/app/components:/app/utils:/app/api_integration
      - PULSE_API_URL=http://django:8000
      - MT5_API_URL=http://mt5:5001
      - MT5_URL=http://mt5:5001
      - DJANGO_API_URL=http://django:8000
      - DJANGO_API_PREFIX=/api/v1
      - BRIDGE_TOKEN=${BRIDGE_TOKEN:-}
    depends_on:
      django:
        condition: service_healthy
    command: >
      streamlit run Home.py --server.port=${STREAMLIT_SERVER_PORT:-8501} --server.enableCORS true --server.enableXsrfProtection false
    restart: unless-stopped
    networks:
      - default
      - traefik-public
    labels:
      <<: *default-labels
      traefik.enable: true
      traefik.docker.network: traefik-public
      traefik.http.routers.dashboard-http.rule: Host(`dash2.zanalytics.app`)
      traefik.http.routers.dashboard-http.entrypoints: http
      traefik.http.routers.dashboard-http.middlewares: https-redirect
      traefik.http.routers.dashboard-https.rule: Host(`dash2.zanalytics.app`)
      traefik.http.routers.dashboard-https.entrypoints: https
      traefik.http.routers.dashboard-https.tls: true
      traefik.http.routers.dashboard-https.tls.certresolver: le
      traefik.http.routers.dashboard-https.service: dashboard-service
      traefik.http.services.dashboard-service.loadbalancer.server.port: 8501
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8501/_stcore/health || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s
    logging: *default-logging

  pulse-bot:
    image: python:3.11-slim
    container_name: pulse-bot
    working_dir: /app
    volumes:
      - .:/app
    env_file:
      - .env
    environment:
      - PYTHONPATH=/app
      - DJANGO_API_URL=http://django:8000
      - DJANGO_API_TOKEN=${DJANGO_API_TOKEN:-}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379/0}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_WHITELIST=${TELEGRAM_CHAT_WHITELIST:-}
    command: sh -lc "pip install --no-cache-dir aiogram requests redis && PYTHONPATH=${PYTHONPATH:-/app} python services/pulse_bot/bot.py"
    depends_on:
      django:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - default

  info:
    build:
      context: .
      dockerfile: services/info/Dockerfile
    container_name: info
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - WIKI_DASHBOARD_PORT=${WIKI_DASHBOARD_PORT:-8503}
    ports:
      - "8503:8503"
    networks:
      - default
      - traefik-public
    labels:
      <<: *default-labels
      traefik.enable: true
      traefik.docker.network: traefik-public
      traefik.http.routers.info.rule: Host(`info.zanalytics.app`)
      traefik.http.routers.info.entrypoints: https
      traefik.http.routers.info.tls.certresolver: le
      traefik.http.services.info.loadbalancer.server.port: 8503
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:8503/ || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

  # whisperer-mcp service removed; see docs/mcp-audit-trail.md for audit history

  mcp:
    build:
      context: ./backend/mcp
    container_name: mcp
    volumes:
      - ./.env:/app/.env
    ports:
    - 8001:8001
    environment:
      - INTERNAL_API_BASE=http://django:8000
      - MCP2_API_KEY=${MCP2_API_KEY:-}
      - DATABASE_URL=${DATABASE_URL:-}
    depends_on:
      - django
    networks:
      - traefik-public
    labels:
      <<: *default-labels
      traefik.enable: true
      traefik.docker.network: traefik-public
      traefik.http.routers.mcp.rule: Host(`mcp2.zanalytics.app`)
      traefik.http.routers.mcp.entrypoints: websecure  
      traefik.http.routers.mcp.tls.certresolver: letsencrypt
      traefik.http.routers.mcp.tls: true
      traefik.http.routers.mcp.service: mcp-service
      traefik.http.services.mcp-service.loadbalancer.server.port: 8001
      traefik.http.middlewares.mcp-strip: null
      traefik.http.routers.mcp.middlewares: null
    restart: unless-stopped
  market-fetcher:
    image: curlimages/curl:8.8.0
    container_name: market-fetcher
    command: ["/bin/sh", "-lc", "while true; do curl -fsS http://django:8000/api/v1/market/fetch || true; sleep 300; done"]
    depends_on:
      django:
        condition: service_started
    restart: unless-stopped
    networks:
      - default
  redis-ml-bridge:
    image: python:3.11-slim
    container_name: redis-ml-bridge
    working_dir: /app
    volumes:
      - .:/app
    environment:
      - REDIS_HOST=${REDIS_HOST:-redis}
      - REDIS_PORT=${REDIS_PORT:-6379}
      - ML_SIGNAL_STREAM=${ML_SIGNAL_STREAM:-ml:signals}
      - ML_RISK_STREAM=${ML_RISK_STREAM:-ml:risk}
    command: sh -lc "pip install --no-cache-dir redis && python services/redis_ml_bridge.py"
    depends_on:
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - default

  mcp2-redis:
    image: redis:7-alpine
    container_name: mcp2-redis
    restart: unless-stopped
    networks:
      - default

  mcp2-pg:
    image: postgres:15-alpine
    container_name: mcp2-pg
    environment:
      POSTGRES_PASSWORD: postgres
    restart: unless-stopped
    networks:
      - default

  mcp2:
    build:
      context: services/mcp2
    container_name: mcp2
    ports:
      - "8002:8002"
    environment:
      - REDIS_URL=redis://mcp2-redis:6379/0
      - DATABASE_URL=postgresql://postgres:postgres@mcp2-pg:5432/postgres
    depends_on:
      mcp2-redis:
        condition: service_started
      mcp2-pg:
        condition: service_started
    restart: unless-stopped
    networks:
      - default

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - "2181:2181"
    networks:
      - data-pipeline

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - data-pipeline

  timescaledb:
    image: timescale/timescaledb:latest-pg15
    container_name: timescaledb
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-timescale}
      POSTGRES_DB: ${POSTGRES_DB:-postgres}
    ports:
      - "5432:5432"
    volumes:
      - timescale-data:/var/lib/postgresql/data
    networks:
      - data-pipeline

volumes:
  grafana-data: {}
  prometheus-data: {}
  redis-data: {}
  postgres-data: {}
  static_volume: {}
  timescale-data: {}

networks:
  default:
    driver: bridge
  data-pipeline:
    driver: bridge
  traefik-public:
    external: true
    name: traefik-public
